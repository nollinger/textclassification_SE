'''
@author: nollr_16.12.21
'''




'''

1. creating functions for preprocessing/word embedding of data.

'''
import nltk
from nltk.stem import WordNetLemmatizer 
from string import punctuation
from string import digits

def remove_umlaut(text): 
    
    """
    Replace umlauts for a given text
    
    :param text: text as string
    :return: manipulated text as str
    """
    
    tempVar = text # local variable
    
    # Using str.replace() 
    
    tempVar = tempVar.replace('ä', 'ae')
    tempVar = tempVar.replace('ö', 'oe')
    tempVar = tempVar.replace('ü', 'ue')
    tempVar = tempVar.replace('Ä', 'Ae')
    tempVar = tempVar.replace('Ö', 'Oe')
    tempVar = tempVar.replace('Ü', 'Ue')
    tempVar = tempVar.replace('ß', 'ss')
    tempVar = tempVar.replace('ãÿ', 'ss')
    tempVar = tempVar.replace('ÃŸ', 'ss')
    tempVar = tempVar.replace('Ã¶', 'oe')
    tempVar = tempVar.replace('Ã¼', 'ue')
    tempVar = tempVar.replace('ã¼', 'ue')
    tempVar = tempVar.replace('Ãœ', 'ue')
    tempVar = tempVar.replace('Ã¤', 'ae')
    
    return tempVar



def punctuation_number(text):
    
    """
    Delete punctuation '!"#$%&\'()*+,-./:;<=>?@[\\]^_`{|}~'
    and digits '0-9'
    
    :return: text without punctuation and digits
    """
    
    remove_pun = str.maketrans('', '', punctuation)
    text_wo_pun = text.translate(remove_pun)
    remove_digits = str.maketrans('', '', digits) #using native string function
    text_wo_num_pun = text_wo_pun.translate(remove_digits)
    return text_wo_num_pun


def tokenize_lemmatize(text):
    
    """
    
    tokenize data and lemmatize
    
    :return: lemmatized data
    """
    
    lemmatizer = WordNetLemmatizer()
    word_list = nltk.word_tokenize(text)
    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])
    
    return lemmatized_output

# import stop words and tokenization
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer



from nltk.corpus import stopwords
german_stop_words = stopwords.words('german')

german_stop_words_to_use = []   # List to hold words after conversion
for word in german_stop_words:
    german_stop_words_to_use.append(remove_umlaut(word))


# !!! option to remove diagnose information !!!
german_stop_words_to_use.extend(['sarkoidose', 'zystische',
                            'fibrose', 'cystische', 'cf', 'zf', 'mukoviszidose', 'morbus', 'boeck']) #remove diagnose names

# tokenize data: (1, 1) means only unigrams, (1, 2) means unigrams and bigrams, and (2, 2) means only bigrams
vects_SVM = CountVectorizer(stop_words=german_stop_words_to_use, ngram_range=(1, 1), min_df=0.01, max_df=0.5)  
vects_NB = CountVectorizer(stop_words=german_stop_words_to_use, ngram_range=(1, 1),  min_df=0.0, max_df=0.5) 
vects_KNN = CountVectorizer(stop_words=german_stop_words_to_use, ngram_range=(1, 1), min_df=0.01, max_df=0.8) 
vects_MLP = CountVectorizer(stop_words=german_stop_words_to_use, ngram_range=(1, 1), min_df=0.02, max_df=0.8) 

tf_idf_SVM = TfidfTransformer(use_idf = False)
tf_idf_NB = TfidfTransformer(use_idf = True) #tf idf 
tf_idf_KNN = TfidfTransformer(use_idf = True)
tf_idf_MLP = TfidfTransformer(use_idf = True)



'''

2. import of the training data

'''


import pandas as pd
import os
import numpy as np


data_lst=[] #list with all the training data
disease=[] #list with disease names

for root, dirs, files in os.walk("C:\\Users\\nollr\\Desktop\\SD_DATEN\\SEMD"): 
   #path with the training-data for both diseases.
   for name in files:
      if name.endswith(".txt"): # data is saved as a txt file.
          file = os.path.join(root, name)
          file= open(file, "r")
          lines= file.read()
          lines = remove_umlaut(lines) #replacing the 'umlaute'
          lines = punctuation_number(lines) #removing punctuation and numbers
          lines = tokenize_lemmatize(lines)
          data_lst.append(lines)
          if name.startswith('CF+'):
              disease.append('E84')
          elif name.startswith('SD+'):
              disease.append('D86')
          file.close()
          


#print (data_lst[0])
#print (disease[0:10])


# import other diseases for validation later
          
other_diseases_text=[]
disease_other=[]

for root, dirs, files in os.walk("C:\\Users\\nollr\\Desktop\\SD_DATEN\\Others"): 
   #path with the training-data for both diseases.
   for name in files:
      if name.endswith(".txt"): # data is saved as a txt file.
          file = os.path.join(root, name)
          file= open(file, "r")
          lines= file.read()
          lines = remove_umlaut(lines) #replacing the 'umlaute'
          lines = punctuation_number(lines) #removing punctuation and numbers
          lines = tokenize_lemmatize(lines)
          other_diseases_text.append(lines)
          if name.startswith('A'):
              disease_other.append("No sufficient similarity to trained cases")
         
          file.close()
          




'''

3. transform data into csv file and create data matrix.

'''

dict = {
        'text': data_lst,
        'SE': disease
        }

df = pd.DataFrame(dict)
df.to_csv('SE1.csv',index=False,header=True) # store data in csv with two columns.
#df

data1 = pd.read_csv('SE1.csv') #text in column 1, classifier in column 2.
se_numpy_array = data1.as_matrix() #create data matrix
X = se_numpy_array[:,0] #text
Y = se_numpy_array[:,1] #classifier


#train_test_split
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(
X, Y, train_size = 200, random_state=7)

   

# other diseases 

dict = {
        'text': other_diseases_text,
        'Disease': disease_other
        }

df = pd.DataFrame(dict)
df.to_csv('Other_Diseases.csv',index=False,header=True) # store data in csv with two columns.
#df

data2 = pd.read_csv('Other_Diseases.csv') #text in column 1, classifier in column 2.
others_numpy_array = data2.as_matrix() #create data matrix
X_others = others_numpy_array[:,0] #text
Y_others = others_numpy_array[:,1] #classifier

# combining text data set

test_set = np.concatenate([X_test, X_others])

test_diagnose = np.concatenate([Y_test, Y_others])


# shape of trainingdata
#word_count_vector=vects_MLP.fit_transform(X_train) # switch MLP to SVM, NB or KNN to get the other shapes
#word_count_vector.shape # (200, 7821) 200 documents with 7821 unique words


'''

4. introducing and creating a pipeline for different classifiers

'''



from sklearn.pipeline import Pipeline
from sklearn.naive_bayes import MultinomialNB #import of classifiers
from sklearn.linear_model import SGDClassifier #sgd: stochastic gradient descent learning
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier #multy layer perceptron (backpropagation)
from sklearn.calibration import CalibratedClassifierCV

def classifier(classifier):
    
    '''
    
    different classifier
    
    '''
    
    if classifier == 'NB':
        classifier = MultinomialNB(alpha=0.01)
    
    elif classifier == 'SVM':
        classifier = SGDClassifier(loss='hinge', penalty='l2',
                                            alpha=0.001, random_state=42)
        classifier= CalibratedClassifierCV(classifier)
    elif classifier == 'KNN':
        classifier = KNeighborsClassifier(n_neighbors=5)
   
    elif classifier == 'MLP':
        classifier = MLPClassifier(max_iter=100,learning_rate='adaptive', activation='relu', hidden_layer_sizes= (100, 100, 100),  alpha=0.001 )
    
    return classifier
    

text_clf_SVM = Pipeline([('vect', vects_SVM),
 ('tfidf', tf_idf_SVM),
 ('clf', classifier('SVM')) # choose classifier
])

text_clf_NB = Pipeline([('vect', vects_NB),
 ('tfidf', tf_idf_NB),
 ('clf', classifier('NB')) # choose classifier
])
  
text_clf_KNN = Pipeline([('vect', vects_KNN),
 ('tfidf', tf_idf_KNN),
 ('clf', classifier('KNN')) # choose classifier
])
    
text_clf_MLP = Pipeline([('vect', vects_MLP),
 ('tfidf', tf_idf_MLP),
 ('clf', classifier('MLP')) # choose classifier
])

  
    
'''

5. GridSearch cross validation (finding best parameters)


'''

text_clf_KNN.get_params().keys() #get classifier keys

from sklearn.model_selection import GridSearchCV
parameters = {
            'vect__ngram_range': [(1, 1), (1, 2)],
                'vect__max_df': (0.2, 0.5, 0.8, 1.0),
                'vect__min_df': (0.0, 0.01, 0.02, 1),
              'tfidf__use_idf': (True, False),
              'clf__alpha': (1e-2, 1e-3, 1e-5, 0.05),
              #'clf__loss':('hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron')
              #'clf__hidden_layer_sizes': [(100,100,100), (100,200,100), (100,)],
                #'clf__solver': ['sgd', 'adam'],
               # 'clf__learning_rate': ['constant','adaptive'],
               # 'clf__activation': ['tanh', 'relu'],
               #'clf__n_neighbors':(12, 15, 20, 25)
}


def gridsearch(classifier):
    

    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, scoring='f1_macro')
    gs_clf = gs_clf.fit(X_train, Y_train)
    

    return gs_clf.best_score_,  gs_clf.best_params_

    

gridsearch(text_clf_SVM)
gridsearch(text_clf_NB)  
gridsearch(text_clf_KNN)  
gridsearch(text_clf_MLP)
   

 
'''

6. Using cross validation

'''


from sklearn.model_selection import cross_validate
from sklearn.model_selection import ShuffleSplit

scoring = ['precision_macro', 'recall_macro']
cv_SVM = ShuffleSplit(n_splits= 100, test_size=0.2, random_state=0) #validation splits and test size
cv_NB = ShuffleSplit(n_splits= 100, test_size=0.2, random_state=0) 
cv_KNN = ShuffleSplit(n_splits= 100, test_size=0.2, random_state=0)
cv_MLP = ShuffleSplit(n_splits= 100, test_size=0.2, random_state=0)
scores_SVM = cross_validate(text_clf_SVM, X_train, Y_train, cv=cv_SVM, scoring=scoring, return_estimator=False)
scores_NB = cross_validate(text_clf_NB, X_train, Y_train, cv=cv_NB, scoring=scoring, return_estimator=False)
scores_KNN = cross_validate(text_clf_KNN, X_train, Y_train, cv=cv_KNN, scoring=scoring, return_estimator=False)
scores_MLP = cross_validate(text_clf_MLP, X_train, Y_train, cv=cv_MLP, scoring=scoring, return_estimator=False)

#sorted(scores.keys())

f1_score_SVM = (2*scores_SVM['test_precision_macro'].mean()*scores_SVM['test_recall_macro'].mean())/(scores_SVM['test_precision_macro'].mean()+scores_SVM['test_recall_macro'].mean())
f1_score_NB = (2*scores_NB['test_precision_macro'].mean()*scores_NB['test_recall_macro'].mean())/(scores_NB['test_precision_macro'].mean()+scores_NB['test_recall_macro'].mean())
f1_score_KNN = (2*scores_KNN['test_precision_macro'].mean()*scores_KNN['test_recall_macro'].mean())/(scores_KNN['test_precision_macro'].mean()+scores_KNN['test_recall_macro'].mean())
f1_score_MLP = (2*scores_MLP['test_precision_macro'].mean()*scores_MLP['test_recall_macro'].mean())/(scores_MLP['test_precision_macro'].mean()+scores_MLP['test_recall_macro'].mean())



print('\n SVM measures:')

print('f1-score: ', f1_score_SVM)
print('precision: ', scores_SVM['test_precision_macro'].mean())
print('recall: ', scores_SVM['test_recall_macro'].mean())

print('\n NB measures:')

print('f1-score: ', f1_score_NB)
print('precision: ', scores_NB['test_precision_macro'].mean())
print('recall: ', scores_NB['test_recall_macro'].mean())

print('\n KNN measures:')

print('f1-score: ', f1_score_KNN)
print('precision: ', scores_KNN['test_precision_macro'].mean())
print('recall: ', scores_KNN['test_recall_macro'].mean())

print('\n MLP measures:')

print('f1-score: ', f1_score_MLP)
print('precision: ', scores_MLP['test_precision_macro'].mean())
print('recall: ', scores_MLP['test_recall_macro'].mean())



# boxplot 
import matplotlib.pyplot as plt 

f1_SVM = [(2*x*y)/(x+y) for x,y in zip(scores_SVM['test_precision_macro'],scores_SVM['test_recall_macro'])]
f1_NB = [(2*x*y)/(x+y) for x,y in zip(scores_NB['test_precision_macro'],scores_NB['test_recall_macro'])]
f1_KNN = [(2*x*y)/(x+y) for x,y in zip(scores_KNN['test_precision_macro'],scores_KNN['test_recall_macro'])]
f1_MLP = [(2*x*y)/(x+y) for x,y in zip(scores_MLP['test_precision_macro'],scores_MLP['test_recall_macro'])]

results, names = [f1_SVM, f1_NB,f1_KNN,f1_MLP],["SVM", "NB", "KNN", "MLP"]

white_diamond = {"markerfacecolor":'w', "marker":'o', "markersize":15}
bp = plt.boxplot(results, labels=names, showmeans=True, patch_artist = True, flierprops=white_diamond, notch = True, meanline = True)
colors = ['#00BFFF', '#FF4040',  
          '#FFFF10', '#F0FFF0'] 
for patch, color in zip(bp['boxes'], colors): 
    patch.set_facecolor(color) 
    
for median in bp['medians']: 
    median.set(color ='black', 
               linewidth = 3) 

for mean in bp['means']:
    mean.set(linewidth = 6, linestyle =":")

plt.tick_params(axis='x', labelsize=40)
plt.tick_params(axis='y', labelsize=40)
plt.xlabel("Klassifikator", fontsize=50, labelpad = 25)
plt.ylabel("F1-Score", fontsize=50, labelpad = 25)  

plt.show()


'''

7. learning curve about the effect of different training sizes on validation scores.


'''

import matplotlib.pyplot as plt 
from sklearn.model_selection import learning_curve


def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,
                        n_jobs=None, train_size=np.linspace(.1, 1.0, 5)):
    


    axes.set_title(title, fontsize=35)
    if ylim is not None:
        axes.set_ylim(*ylim)
    if title is title1:   
        axes.set_ylabel("F1-Score", fontsize=30, labelpad = 25)
    axes.set_xlabel("Training examples", fontsize=30,labelpad = 25)
    

    train_sizes, train_scores, test_scores = \
        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,
                       train_sizes=train_size, scoring ='f1_macro'
                       )
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    
      
    axes.grid()
    axes.fill_between(train_sizes, train_scores_mean - train_scores_std,
                         train_scores_mean + train_scores_std, alpha=0.1,
                         color="r")
    axes.fill_between(train_sizes, test_scores_mean - test_scores_std,
                         test_scores_mean + test_scores_std, alpha=0.1,
                         color="g")
    axes.plot(train_sizes, train_scores_mean, 'o-', color="r", markersize=20,
                 label="Training score")
    axes.plot(train_sizes, test_scores_mean, '^-', color="g", markersize=20,
                 label="Cross-validation score")
    axes.legend(loc="lower right", fontsize=30)
    
    axes.tick_params(axis='x', labelsize=30)
    axes.tick_params(axis='y', labelsize=30)
    
    return plt, train_scores_mean, test_scores_mean, train_scores_std,  test_scores_std, test_scores



fig,axes = plt.subplots(1, 4, figsize=(20, 25))

title1 = "SVM"

plot_learning_curve(text_clf_SVM, title1, X_train, y=Y_train, axes=axes[0], ylim=(0.6, 1.01),
                    cv=cv_SVM, n_jobs=4)



title2 = "NB"

plot_learning_curve(text_clf_NB, title2, X_train, y=Y_train, axes=axes[1], ylim=(0.6, 1.01),
                    cv=cv_NB, n_jobs=4)



title3 = "KNN"

plot_learning_curve(text_clf_KNN, title3, X_train, y=Y_train, axes=axes[2], ylim=(0.6, 1.01),
                    cv=cv_KNN, n_jobs=4)

title4 = "MLP"

plot_learning_curve(text_clf_MLP, title4, X_train, y=Y_train, axes=axes[3], ylim=(0.6, 1.01),
                    cv=cv_MLP, n_jobs=4)



plt.show()


'''

8. prediction of new cases

'''


from sklearn.metrics import f1_score, precision_score, recall_score
from sklearn.ensemble import VotingClassifier

def pred_probs(classifier):
    

    pred_proba = classifier.fit(X_train, Y_train)
    
    if classifier == text_clf_SVM:
         pred_proba = pred_proba.decision_function(test_set)
    else:
         pred_proba = pred_proba.predict_proba(test_set)
    
    return pred_proba



def prediction(classifier):
    
    new_pred =[]
    case = 0
    
    if classifier == text_clf_SVM:
        for value in pred_probs(classifier): 
            
            if value >= 0.93 or value <= -0.93:
                   pred = classifier.fit(X_train, Y_train).predict([test_set[case]])
        
            else:
                pred = (["No sufficient similarity to trained cases"])
            case += 1
            new_pred.extend(pred)
    
    else:
        for pairs in pred_probs(classifier): 
            if max(pairs) >= 0.998: #threshold parameter, must be at least 99,8% confident for prediction
                   pred = classifier.fit(X_train, Y_train).predict([test_set[case]])
            elif max(pairs) < 0.998:
                pred = (["No sufficient similarity to trained cases"])
            case += 1
            new_pred.extend(pred)
           
    return new_pred

SVM = prediction(text_clf_SVM)
NB = prediction(text_clf_NB)
KNN = prediction(text_clf_KNN)
MLP = prediction(text_clf_MLP)


print('\nSVM_PRECISION: ', precision_score(SVM, test_diagnose, average='macro'))
print('SVM_RECALL: ', recall_score(SVM, test_diagnose, average='macro'))
print('SVM_F1: ', (2*precision_score(SVM, test_diagnose, average='macro')*recall_score(SVM, test_diagnose, average='macro'))/(precision_score(SVM, test_diagnose, average='macro')+recall_score(SVM, test_diagnose, average='macro')))


print('\nNB_PRECISION: ', precision_score(NB, test_diagnose, average='macro'))
print('NB_RECALL: ', recall_score(NB, test_diagnose, average='macro'))
print('NB_F1: ', (2*precision_score(NB, test_diagnose, average='macro')*recall_score(NB, test_diagnose, average='macro'))/(precision_score(NB, test_diagnose, average='macro')+recall_score(NB, test_diagnose, average='macro')))


print('\nKNN_PRECISION: ', precision_score(KNN, test_diagnose, average='macro'))
print('KNN_RECALL: ', recall_score(KNN, test_diagnose, average='macro'))
print('KNN_F1: ', (2*precision_score(KNN, test_diagnose, average='macro')*recall_score(KNN, test_diagnose, average='macro'))/(precision_score(KNN, test_diagnose, average='macro')+recall_score(KNN, test_diagnose, average='macro')))


print('\nMLP_PRECISION: ', precision_score(MLP, test_diagnose, average='macro'))
print('MLP_RECALL: ', recall_score(MLP, test_diagnose, average='macro'))
print('MLP_F1: ', (2*precision_score(MLP, test_diagnose, average='macro')*recall_score(MLP, test_diagnose, average='macro'))/(precision_score(MLP, test_diagnose, average='macro')+recall_score(MLP, test_diagnose, average='macro')))



# prediction validation just for test cases with trained label

pred_SVM = text_clf_SVM.fit(X_train, Y_train).predict(X_test)
pred_NB = text_clf_NB.fit(X_train, Y_train).predict(X_test)
pred_KNN = text_clf_KNN.fit(X_train, Y_train).predict(X_test)
pred_MLP = text_clf_MLP.fit(X_train, Y_train).predict(X_test)


print('\nSVM_PRECISION: ', precision_score(pred_SVM, Y_test, average='macro'))
print('SVM_RECALL: ', recall_score(pred_SVM, Y_test, average='macro'))
print('SVM_F1: ', (2*precision_score(pred_SVM, Y_test, average='macro')*recall_score(pred_SVM, Y_test, average='macro'))/(precision_score(pred_SVM, Y_test, average='macro')+recall_score(pred_SVM, Y_test, average='macro')))


print('\nNB_PRECISION: ', precision_score(pred_NB, Y_test, average='macro'))
print('NB_RECALL: ', recall_score(pred_NB, Y_test, average='macro'))
print('NB_F1: ', (2*precision_score(pred_NB, Y_test, average='macro')*recall_score(pred_NB, Y_test, average='macro'))/(precision_score(pred_NB, Y_test, average='macro')+recall_score(pred_NB, Y_test, average='macro')))


print('\nKNN_PRECISION: ', precision_score(pred_KNN, Y_test, average='macro'))
print('KNN_RECALL: ', recall_score(pred_KNN, Y_test, average='macro'))
print('KNN_F1: ', (2*precision_score(pred_KNN, Y_test, average='macro')*recall_score(pred_KNN, Y_test, average='macro'))/(precision_score(pred_KNN, Y_test, average='macro')+recall_score(pred_KNN, Y_test, average='macro')))


print('\nMLP_PRECISION: ', precision_score(pred_MLP, Y_test, average='macro'))
print('MLP_RECALL: ', recall_score(pred_MLP, Y_test, average='macro'))
print('MLP_F1: ', (2*precision_score(pred_MLP, Y_test, average='macro')*recall_score(pred_MLP, Y_test, average='macro'))/(precision_score(pred_MLP, Y_test, average='macro')+recall_score(pred_MLP, Y_test, average='macro')))






'''

8. wordclouds

'''





    
# WordCloud with tf idf
    
    
import matplotlib.pyplot as plt 
from sklearn.feature_extraction.text import TfidfVectorizer
from wordcloud import WordCloud


german_stop_words_to_use.extend(['ja', 'nein', 'gutem', 'empfehlen', 'habe', 'ambulanz', 'telefon', 'durchgefuehrt', 'ausgang',
                            'soll', 'unter', 'weitere', 'erfolgte', 'vorstellung', 'sowie', 'ohne', 'heute', 'vergleich',
                            'war', 'sollte', 'hier', 'eingang', 'auch', 'durch', 'stueck', 'da', 'weiteren', 'bzw', 'zeigte',
                            'arztbrief', 'patienten', 'aufnahme', 'untersuchung', 'erfolgt', 'wurde', 'patient', 'patientin', 'ca', 'seit', 'verlauf'])


vectorizer = TfidfVectorizer(sublinear_tf=True,
                        min_df=4, max_df = 0.97, norm='l2',
                        encoding='latin-1',
                        ngram_range=(1, 1),
                        stop_words=german_stop_words_to_use)

rare_diseases =['E84', 'D86']


for se in rare_diseases:
    s=data1[data1.SE==se]
    lower_s = s['text'].str.lower()
    text=lower_s.tolist() # creates list with all documents from the specific se

    X = vectorizer.fit_transform(text)
    feature_names = vectorizer.get_feature_names()
    dense = X.todense()
    lst1 = dense.tolist()
    df = pd.DataFrame(lst1, columns=feature_names)
    frequencies = df.T.sum(axis=1)
    
    wordcloud = WordCloud(width=3000, height=2000,
                    min_font_size = 5, max_font_size=200,
                    max_words= 70, background_color="white",
                    mode="RGBA").generate_from_frequencies(frequencies)
    plt.axis("off")
    
    plt.imshow(wordcloud
               , interpolation="bilinear")
    plt.figure()
    plt.show()
        
    print('Figure', rare_diseases.index(se) + 1,' :', se)
    


